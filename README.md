# `adawhatever`
A collection of various stochastic gradient descent (SGD) solvers implemented in MATLAB.

## Introduction
Stochastic gradient descent is a state of the art optimisation method in machine learning. It suits the concept of learning on many data points very well and outperforms many _theoretically_ superior second-order methods.

All fancy SGD solvers are readily available in every machine learning framework, e.g. [Lasagne](https://github.com/Lasagne/Lasagne). However, machine learning usage is not the goal of this repo. Instead, it attempts to facilitate transfer of novel algorithms from machine learning to other, mostly engineering, applications. These communities tend to speak MATLAB and not Python; this motivates the language choice.

Furthermore, 'classic' optimisation terms are used instead of machine learning lingo, e.g.:
* learning rate -> step size
* parameters -> decision variables
* hyperparameters ~ solver parameters

## How to use it

TODO :warning:
